; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; NOTE: Both functions must emit same instruction schedule with -guided-src
;RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mcpu=skx | FileCheck --check-prefixes=DEFAULT-SCHED %s
;RUN: llc < %s -pre-RA-sched=guided-src -mtriple=x86_64-unknown-linux-gnu -mcpu=skx | FileCheck --check-prefixes=GUIDED_SRC-SCHED %s

define i32 @clz_i128(i64, i64)  {
; DEFAULT-SCHED-LABEL: clz_i128:
; DEFAULT-SCHED:       # BB#0:
; DEFAULT-SCHED-NEXT:    lzcntq %rsi, %rcx
; DEFAULT-SCHED-NEXT:    xorl %edx, %edx
; DEFAULT-SCHED-NEXT:    lzcntq %rdi, %rax
; DEFAULT-SCHED-NEXT:    cmovael %edx, %ecx
; DEFAULT-SCHED-NEXT:    addl %ecx, %eax
; DEFAULT-SCHED-NEXT:    # kill: %EAX<def> %EAX<kill> %RAX<kill>
; DEFAULT-SCHED-NEXT:    retq
;
; GUIDED_SRC-SCHED-LABEL: clz_i128:
; GUIDED_SRC-SCHED:       # BB#0:
; GUIDED_SRC-SCHED-NEXT:    lzcntq %rsi, %rcx
; GUIDED_SRC-SCHED-NEXT:    xorl %edx, %edx
; GUIDED_SRC-SCHED-NEXT:    lzcntq %rdi, %rax
; GUIDED_SRC-SCHED-NEXT:    cmovael %edx, %ecx
; GUIDED_SRC-SCHED-NEXT:    addl %ecx, %eax
; GUIDED_SRC-SCHED-NEXT:    # kill: %EAX<def> %EAX<kill> %RAX<kill>
; GUIDED_SRC-SCHED-NEXT:    retq
  %3 = tail call i64 @llvm.ctlz.i64(i64 %1, i1 false)
  %4 = tail call i64 @llvm.ctlz.i64(i64 %0, i1 false)
  %5 = icmp ne i64 %0, 0
  %6 = select i1 %5, i64 0, i64 %3
  %7 = add nuw nsw i64 %6, %4
  %8 = trunc i64 %7 to i32
  ret i32 %8
}

define i32 @clz_i128_swap(i64, i64)  {
; DEFAULT-SCHED-LABEL: clz_i128_swap:
; DEFAULT-SCHED:       # BB#0:
; DEFAULT-SCHED-NEXT:    lzcntq %rdi, %rax
; DEFAULT-SCHED-NEXT:    lzcntq %rsi, %rcx
; DEFAULT-SCHED-NEXT:    xorl %edx, %edx
; DEFAULT-SCHED-NEXT:    testq %rdi, %rdi
; DEFAULT-SCHED-NEXT:    cmovnel %edx, %ecx
; DEFAULT-SCHED-NEXT:    addl %ecx, %eax
; DEFAULT-SCHED-NEXT:    # kill: %EAX<def> %EAX<kill> %RAX<kill>
; DEFAULT-SCHED-NEXT:    retq
;
; GUIDED_SRC-SCHED-LABEL: clz_i128_swap:
; GUIDED_SRC-SCHED:       # BB#0:
; GUIDED_SRC-SCHED-NEXT:    lzcntq %rsi, %rcx
; GUIDED_SRC-SCHED-NEXT:    xorl %edx, %edx
; GUIDED_SRC-SCHED-NEXT:    lzcntq %rdi, %rax
; GUIDED_SRC-SCHED-NEXT:    cmovael %edx, %ecx
; GUIDED_SRC-SCHED-NEXT:    addl %ecx, %eax
; GUIDED_SRC-SCHED-NEXT:    # kill: %EAX<def> %EAX<kill> %RAX<kill>
; GUIDED_SRC-SCHED-NEXT:    retq
  %3 = tail call i64 @llvm.ctlz.i64(i64 %0, i1 false) ;   <-- SWAP
  %4 = tail call i64 @llvm.ctlz.i64(i64 %1, i1 false) ;   <-- SWAP
  %5 = icmp ne i64 %0, 0
  %6 = select i1 %5, i64 0, i64 %4
  %7 = add nuw nsw i64 %6, %3
  %8 = trunc i64 %7 to i32
  ret i32 %8
}
declare i64 @llvm.ctlz.i64(i64, i1)

